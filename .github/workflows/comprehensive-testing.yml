name: Comprehensive Testing Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run security tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        cd services/core-api
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run unit tests
      run: |
        cd services/core-api
        python -m pytest tests/ \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --junit-xml=test-results/unit-tests.xml \
          --cov-fail-under=70
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: services/core-api/coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results
        path: services/core-api/test-results/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        cd services/core-api
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        TESTING: true
      run: |
        cd services/core-api
        python -m pytest tests/integration/ \
          --junit-xml=test-results/integration-tests.xml \
          -v
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: services/core-api/test-results/

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install security tools
      run: |
        pip install safety bandit semgrep
        cd services/core-api
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run safety check
      run: |
        cd services/core-api
        safety check --json --output safety-report.json || true
    
    - name: Run bandit security linting
      run: |
        cd services/core-api
        bandit -r app/ -f json -o bandit-report.json || true
    
    - name: Run semgrep security scan
      run: |
        cd services/core-api
        semgrep --config=auto --json --output=semgrep-report.json app/ || true
    
    - name: Run security tests
      run: |
        cd services/core-api
        python -m pytest tests/security/ \
          --junit-xml=test-results/security-tests.xml \
          -v
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          services/core-api/*-report.json
          services/core-api/test-results/

  compliance-tests:
    name: Compliance Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        cd services/core-api
        pip install -r requirements.txt
        pip install -r requirements-test.txt
    
    - name: Run compliance tests
      run: |
        cd services/core-api
        python -m pytest tests/security/test_privacy_compliance.py \
          --junit-xml=test-results/compliance-tests.xml \
          -v
    
    - name: Upload compliance results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: compliance-test-results
        path: services/core-api/test-results/

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: pgvector/pgvector:pg15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: services/chat-widget/package-lock.json
    
    - name: Install Python dependencies
      run: |
        cd services/core-api
        pip install -r requirements.txt
    
    - name: Install Node.js dependencies
      run: |
        cd services/chat-widget
        npm ci
    
    - name: Install Playwright
      run: |
        cd services/core-api/tests/e2e
        npm ci
        npx playwright install --with-deps
    
    - name: Start services
      run: |
        cd services/core-api
        uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        cd ../chat-widget
        npm run dev &
        sleep 10
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        TESTING: true
    
    - name: Run E2E tests
      run: |
        cd services/core-api/tests/e2e
        npx playwright test --reporter=html,junit
    
    - name: Upload E2E results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: |
          services/core-api/tests/e2e/test-results/
          services/core-api/tests/e2e/playwright-report/

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        cd services/core-api
        pip install -r requirements.txt
        cd tests/e2e
        npm ci
        npx playwright install --with-deps
    
    - name: Start services
      run: |
        cd services/core-api
        uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        sleep 10
      env:
        TESTING: true
    
    - name: Run performance tests
      run: |
        cd services/core-api/tests/e2e
        npx playwright test tests/performance.spec.js --reporter=html,junit
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: services/core-api/tests/e2e/test-results/

  vulnerability-scan:
    name: Vulnerability Scan
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'push'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
    
    - name: Install Python security tools
      run: |
        pip install safety bandit
        cd services/core-api
        pip install -r requirements.txt
    
    - name: Python dependency vulnerability scan
      run: |
        cd services/core-api
        safety check --json --output vulnerability-report.json
    
    - name: JavaScript dependency vulnerability scan
      run: |
        cd services/chat-widget
        npm audit --audit-level=moderate --json > ../core-api/npm-audit-report.json
    
    - name: Code security scan
      run: |
        cd services/core-api
        bandit -r app/ -f json -o code-security-report.json
    
    - name: Upload vulnerability reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: vulnerability-reports
        path: services/core-api/*-report.json

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests, compliance-tests, e2e-tests]
    if: always()
    
    steps:
    - name: Download all test results
      uses: actions/download-artifact@v3
    
    - name: Generate test summary
      run: |
        echo "# Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check each job status
        if [ "${{ needs.unit-tests.result }}" == "success" ]; then
          echo "✅ Unit Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Unit Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.integration-tests.result }}" == "success" ]; then
          echo "✅ Integration Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Integration Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.security-tests.result }}" == "success" ]; then
          echo "✅ Security Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Security Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.compliance-tests.result }}" == "success" ]; then
          echo "✅ Compliance Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Compliance Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "${{ needs.e2e-tests.result }}" == "success" ]; then
          echo "✅ E2E Tests: PASSED" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ E2E Tests: FAILED" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "📊 **Overall Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY